"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __objRest = (source, exclude) => {
  var target = {};
  for (var prop in source)
    if (__hasOwnProp.call(source, prop) && exclude.indexOf(prop) < 0)
      target[prop] = source[prop];
  if (source != null && __getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(source)) {
      if (exclude.indexOf(prop) < 0 && __propIsEnum.call(source, prop))
        target[prop] = source[prop];
    }
  return target;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};

// src/llm/llama-cpp.ts
var llama_cpp_exports = {};
__export(llama_cpp_exports, {
  LLamaCpp: () => LLamaCpp
});
module.exports = __toCommonJS(llama_cpp_exports);
var import_llama_cpp = require("@llama-node/llama-cpp");
var LLamaCpp = class {
  load(config) {
    const _a = config, { path, enableLogging } = _a, rest = __objRest(_a, ["path", "enableLogging"]);
    this.instance = import_llama_cpp.LLama.load(path, rest, enableLogging);
  }
  createCompletion(params, callback) {
    return __async(this, null, function* () {
      let completed = false;
      const errors = [];
      return new Promise((res, rej) => {
        this.instance.inference(params, (response) => {
          var _a;
          switch (response.type) {
            case import_llama_cpp.InferenceResultType.Data: {
              const data = {
                token: response.data.token,
                completed: !!response.data.completed
              };
              if (data.completed) {
                completed = true;
              }
              callback(data);
              break;
            }
            case import_llama_cpp.InferenceResultType.End: {
              if (errors.length) {
                rej(new Error(errors.join("\n")));
              } else {
                res(completed);
              }
              break;
            }
            case import_llama_cpp.InferenceResultType.Error: {
              errors.push((_a = response.message) != null ? _a : "Unknown Error");
              break;
            }
          }
        });
      });
    });
  }
  getEmbedding(params) {
    return __async(this, null, function* () {
      return new Promise((res, rej) => {
        this.instance.getWordEmbedding(params, (response) => {
          var _a;
          switch (response.type) {
            case import_llama_cpp.EmbeddingResultType.Data:
              res((_a = response.data) != null ? _a : []);
              break;
            case import_llama_cpp.EmbeddingResultType.Error:
              rej(new Error("Unknown Error"));
              break;
          }
        });
      });
    });
  }
  getDefaultEmbedding(text) {
    return __async(this, null, function* () {
      return this.getEmbedding({
        nThreads: 4,
        nTokPredict: 1024,
        topK: 40,
        topP: 0.1,
        temp: 0.1,
        repeatPenalty: 1,
        prompt: text
      });
    });
  }
  tokenize(params) {
    return __async(this, null, function* () {
      return new Promise((res, rej) => {
        this.instance.tokenize(params.content, params.nCtx, (response) => {
          if (response.type === import_llama_cpp.TokenizeResultType.Data) {
            res(response.data);
          } else {
            rej(new Error("Unknown Error"));
          }
        });
      });
    });
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  LLamaCpp
});
//# sourceMappingURL=llama-cpp.cjs.map