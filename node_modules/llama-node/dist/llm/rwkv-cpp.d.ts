import { Rwkv, RwkvInvocation } from '@llama-node/rwkv-cpp';
import { I as ILLM } from '../llm.d-120996aa.js';

interface LoadConfig {
    modelPath: string;
    tokenizerPath: string;
    nThreads: number;
    enableLogging: boolean;
}
interface TokenizeArguments {
    content: string;
}
declare class RwkvCpp implements ILLM<Rwkv, LoadConfig, RwkvInvocation, unknown, TokenizeArguments> {
    instance: Rwkv;
    load(config: LoadConfig): void;
    createCompletion(params: RwkvInvocation, callback: (data: {
        token: string;
        completed: boolean;
    }) => void): Promise<boolean>;
    tokenize(params: TokenizeArguments): Promise<number[]>;
}

export { LoadConfig, RwkvCpp, TokenizeArguments };
