{"version":3,"sources":["../../src/extensions/langchain.ts"],"sourcesContent":["// import { AsyncCaller } from \"langchain/dist/util/async_caller.js\";\nimport { Embeddings, type EmbeddingsParams } from \"langchain/embeddings/base\";\nimport type { LLama } from \"..\";\n\nexport class LLamaEmbeddings extends Embeddings {\n    llm: LLama;\n\n    constructor(params: EmbeddingsParams, llm: LLama) {\n        super(params);\n        if ((params.maxConcurrency ?? 1) > 1) {\n            console.warn(\n                \"maxConcurrency > 1 not officially supported for llama-node, use at your own risk\"\n            );\n        }\n        this.llm = llm;\n    }\n\n    embedDocuments(documents: string[]): Promise<number[][]> {\n        const promises = documents.map((doc) =>\n            this.llm.getDefaultEmbeddings(doc)\n        );\n        return Promise.all(promises);\n    }\n\n    embedQuery(document: string): Promise<number[]> {\n        return this.llm.getDefaultEmbeddings(document);\n    }\n}\n"],"mappings":";AACA,SAAS,kBAAyC;AAG3C,IAAM,kBAAN,cAA8B,WAAW;AAAA,EAG5C,YAAY,QAA0B,KAAY;AAPtD;AAQQ,UAAM,MAAM;AACZ,UAAK,YAAO,mBAAP,YAAyB,KAAK,GAAG;AAClC,cAAQ;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AACA,SAAK,MAAM;AAAA,EACf;AAAA,EAEA,eAAe,WAA0C;AACrD,UAAM,WAAW,UAAU;AAAA,MAAI,CAAC,QAC5B,KAAK,IAAI,qBAAqB,GAAG;AAAA,IACrC;AACA,WAAO,QAAQ,IAAI,QAAQ;AAAA,EAC/B;AAAA,EAEA,WAAW,UAAqC;AAC5C,WAAO,KAAK,IAAI,qBAAqB,QAAQ;AAAA,EACjD;AACJ;","names":[]}